{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7893f4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ['TSLA', 'BND', 'SPY'] from 2015-07-01 to 2025-07-31 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amenzz\\AppData\\Local\\Temp\\ipykernel_4284\\769387050.py:30: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(t, start=start, end=end, progress=False)\n",
      "C:\\Users\\Amenzz\\AppData\\Local\\Temp\\ipykernel_4284\\769387050.py:30: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(t, start=start, end=end, progress=False)\n",
      "C:\\Users\\Amenzz\\AppData\\Local\\Temp\\ipykernel_4284\\769387050.py:30: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(t, start=start, end=end, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing ticker: TSLA\n",
      "\n",
      "TSLA - head:\n",
      "Price           Close       High        Low       Open     Volume      Price Daily_Return  Return_Z Rolling_Mean_30 Rolling_Std_30\n",
      "Ticker           TSLA       TSLA       TSLA       TSLA       TSLA                                                                 \n",
      "Date                                                                                                                              \n",
      "2015-07-01  17.943333  18.174667  17.856667  18.073999   31518000  17.943333          NaN       NaN             NaN            NaN\n",
      "2015-07-02  18.667999  18.830000  18.220667  18.680000  107458500  18.667999     0.040386  1.034139             NaN            NaN\n",
      "2015-07-06  18.648001  18.779333  18.420000  18.591999   61828500  18.648001    -0.001071 -0.077763             NaN            NaN\n",
      "\n",
      "TSLA - describe (Price):\n",
      "count    2535.000000\n",
      "mean      131.963002\n",
      "std       120.914904\n",
      "min         9.578000\n",
      "25%        18.967667\n",
      "50%        94.571335\n",
      "75%       236.761665\n",
      "max       479.859985\n",
      "\n",
      "ADF test for TSLA price: ADF=-1.4189, p=0.5732, stationary=False\n",
      "ADF test for TSLA returns: ADF=-34.6811, p=0.0000, stationary=True\n",
      "\n",
      "TSLA - outliers (|z|>3) count: 41\n",
      "Price           Price Daily_Return  Return_Z\n",
      "Ticker                                      \n",
      "Date                                        \n",
      "2018-08-02  23.302668     0.161880  4.292619\n",
      "2018-09-28  17.651333    -0.139015 -3.777444\n",
      "2018-10-01  20.713333     0.173471  4.603497\n",
      "2018-10-23  19.609333     0.127189  3.362199\n",
      "2019-01-18  20.150667    -0.129711 -3.527904\n",
      "Saved: outputs\\TSLA_processed.csv\n",
      "Saved plot: outputs\\plots\\TSLA_price_rolling.png\n",
      "Saved plot: outputs\\plots\\TSLA_daily_returns.png\n",
      "Saved plot: outputs\\plots\\TSLA_returns_hist.png\n",
      "\n",
      "============================================================\n",
      "Processing ticker: BND\n",
      "\n",
      "BND - head:\n",
      "Price           Close       High        Low       Open   Volume      Price Daily_Return  Return_Z Rolling_Mean_30 Rolling_Std_30\n",
      "Ticker            BND        BND        BND        BND      BND                                                                 \n",
      "Date                                                                                                                            \n",
      "2015-07-01  60.816746  60.914471  60.764123  60.794194  5399300  60.816746          NaN       NaN             NaN            NaN\n",
      "2015-07-02  60.967091  61.027232  60.937020  60.937020  1060100  60.967091     0.002472  0.692089             NaN            NaN\n",
      "2015-07-06  61.177540  61.222649  61.057263  61.222649  2210700  61.177540     0.003452  0.975291             NaN            NaN\n",
      "\n",
      "BND - describe (Price):\n",
      "count    2535.000000\n",
      "mean       68.469188\n",
      "std         4.554602\n",
      "min        60.779163\n",
      "25%        64.654362\n",
      "50%        67.604889\n",
      "75%        71.891136\n",
      "max        77.318275\n",
      "\n",
      "ADF test for BND price: ADF=-1.5363, p=0.5155, stationary=False\n",
      "ADF test for BND returns: ADF=-9.8898, p=0.0000, stationary=True\n",
      "\n",
      "BND - outliers (|z|>3) count: 26\n",
      "Price           Price Daily_Return   Return_Z\n",
      "Ticker                                       \n",
      "Date                                         \n",
      "2020-03-10  74.094521    -0.013445  -3.908772\n",
      "2020-03-11  72.691193    -0.018940  -5.497083\n",
      "2020-03-12  68.737892    -0.054385 -15.742661\n",
      "2020-03-13  71.638687     0.042201  12.175846\n",
      "2020-03-16  72.391731     0.010512   3.015970\n",
      "Saved: outputs\\BND_processed.csv\n",
      "Saved plot: outputs\\plots\\BND_price_rolling.png\n",
      "Saved plot: outputs\\plots\\BND_daily_returns.png\n",
      "Saved plot: outputs\\plots\\BND_returns_hist.png\n",
      "\n",
      "============================================================\n",
      "Processing ticker: SPY\n",
      "\n",
      "SPY - head:\n",
      "Price            Close        High         Low        Open     Volume       Price Daily_Return  Return_Z Rolling_Mean_30 Rolling_Std_30\n",
      "Ticker             SPY         SPY         SPY         SPY        SPY                                                                  \n",
      "Date                                                                                                                                   \n",
      "2015-07-01  174.917114  175.363889  174.124717  175.110995  135979900  174.917114          NaN       NaN             NaN            NaN\n",
      "2015-07-02  174.756943  175.566203  174.335456  175.397611  104373700  174.756943    -0.000916 -0.129713             NaN            NaN\n",
      "2015-07-06  174.259567  175.043527  173.256426  173.458745  117975400  174.259567    -0.002846 -0.297712             NaN            NaN\n",
      "\n",
      "SPY - describe (Price):\n",
      "count    2535.000000\n",
      "mean      334.193733\n",
      "std       126.427703\n",
      "min       155.869797\n",
      "25%       230.083168\n",
      "50%       305.264435\n",
      "75%       420.350525\n",
      "max       637.099976\n",
      "\n",
      "ADF test for SPY price: ADF=0.6908, p=0.9897, stationary=False\n",
      "ADF test for SPY returns: ADF=-16.2644, p=0.0000, stationary=True\n",
      "\n",
      "SPY - outliers (|z|>3) count: 35\n",
      "Price            Price Daily_Return  Return_Z\n",
      "Ticker                                       \n",
      "Date                                         \n",
      "2015-08-24  159.743561    -0.042107 -3.714484\n",
      "2015-08-26  163.924789     0.038394  3.291343\n",
      "2016-06-24  175.040771    -0.035909 -3.175106\n",
      "2018-02-05  234.272659    -0.041822 -3.689729\n",
      "2018-02-08  228.680573    -0.037509 -3.314343\n",
      "Saved: outputs\\SPY_processed.csv\n",
      "Saved plot: outputs\\plots\\SPY_price_rolling.png\n",
      "Saved plot: outputs\\plots\\SPY_daily_returns.png\n",
      "Saved plot: outputs\\plots\\SPY_returns_hist.png\n",
      "Saved: outputs\\summary_metrics.csv\n",
      "\n",
      "Summary metrics (head):\n",
      "      start_date    end_date      mean       std    VaR_95  Sharpe_annual  ADF_price_pvalue  ADF_returns_pvalue  outliers_count\n",
      "TSLA  2015-07-01  2025-07-30  0.001828  0.037285 -0.054663       0.778340          0.573196        0.000000e+00              41\n",
      "BND   2015-07-01  2025-07-30  0.000078  0.003460 -0.004899       0.356879          0.515508        3.583539e-17              26\n",
      "SPY   2015-07-01  2025-07-30  0.000575  0.011491 -0.017195       0.794072          0.989653        3.539320e-29              35\n",
      "\n",
      "Completed Task 1 in 0:00:11.428681. Outputs saved in 'outputs' directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration\n",
    "# ----------------------------\n",
    "TICKERS = [\"TSLA\", \"BND\", \"SPY\"]\n",
    "START_DATE = \"2015-07-01\"\n",
    "END_DATE = \"2025-07-31\"\n",
    "ROLL_WINDOW = 30  # days for rolling statistics\n",
    "OUT_DIR = \"outputs\"\n",
    "PLOTS_DIR = os.path.join(OUT_DIR, \"plots\")\n",
    "np.random.seed(42)\n",
    "\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def download_data(tickers, start, end):\n",
    "    print(f\"Downloading {tickers} from {start} to {end} ...\")\n",
    "    data = {}\n",
    "    for t in tickers:\n",
    "        df = yf.download(t, start=start, end=end, progress=False)\n",
    "        if df.empty:\n",
    "            print(f\"Warning: no data downloaded for {t}.\")\n",
    "        # Ensure Date is index as DatetimeIndex\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        data[t] = df\n",
    "    return data\n",
    "\n",
    "def fill_missing(df):\n",
    "    # Forward then backward fill and drop remaining NaNs if any\n",
    "    df = df.copy()\n",
    "    df = df.ffill().bfill()\n",
    "    df = df.dropna(how=\"all\")\n",
    "    return df\n",
    "\n",
    "def compute_features(df):\n",
    "    df = df.copy()\n",
    "    # Adjusted close exists in Yahoo; prefer 'Adj Close' for returns if present\n",
    "    price_col = \"Adj Close\" if \"Adj Close\" in df.columns else \"Close\"\n",
    "    df[\"Price\"] = df[price_col]\n",
    "    df[\"Daily_Return\"] = df[\"Price\"].pct_change()\n",
    "    df[\"Return_Z\"] = (df[\"Daily_Return\"] - df[\"Daily_Return\"].mean()) / df[\"Daily_Return\"].std()\n",
    "    df[f\"Rolling_Mean_{ROLL_WINDOW}\"] = df[\"Price\"].rolling(window=ROLL_WINDOW).mean()\n",
    "    df[f\"Rolling_Std_{ROLL_WINDOW}\"] = df[\"Price\"].rolling(window=ROLL_WINDOW).std()\n",
    "    return df\n",
    "\n",
    "def adf_test(series, title=\"Series\"):\n",
    "    series = series.dropna()\n",
    "    if series.shape[0] < 10:\n",
    "        return {\"ADF Statistic\": np.nan, \"p-value\": np.nan, \"usedlags\": np.nan, \"nobs\": series.shape[0], \"stationary\": None}\n",
    "    res = adfuller(series, autolag=\"AIC\")\n",
    "    out = {\n",
    "        \"ADF Statistic\": res[0],\n",
    "        \"p-value\": res[1],\n",
    "        \"usedlags\": res[2],\n",
    "        \"nobs\": res[3],\n",
    "        \"stationary\": res[1] <= 0.05\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def compute_risk_metrics(returns):\n",
    "    returns = returns.dropna()\n",
    "    if returns.empty:\n",
    "        return {\"mean\": np.nan, \"std\": np.nan, \"VaR_95\": np.nan, \"Sharpe_annual\": np.nan}\n",
    "    mean = returns.mean()\n",
    "    std = returns.std()\n",
    "    VaR_95 = np.percentile(returns, 5)  # 5th percentile\n",
    "    sharpe = (mean / std) * np.sqrt(252) if std != 0 else np.nan\n",
    "    return {\"mean\": mean, \"std\": std, \"VaR_95\": VaR_95, \"Sharpe_annual\": sharpe}\n",
    "\n",
    "def save_df(df, path):\n",
    "    df.to_csv(path)\n",
    "    print(f\"Saved: {path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Main workflow\n",
    "# ----------------------------\n",
    "def main():\n",
    "    start_time = datetime.now()\n",
    "    # 1) Download\n",
    "    data = download_data(TICKERS, START_DATE, END_DATE)\n",
    "\n",
    "    summary_metrics = {}\n",
    "    for ticker, df in data.items():\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"Processing ticker: {ticker}\")\n",
    "        if df.empty:\n",
    "            print(f\"Skipping {ticker} because no data.\")\n",
    "            continue\n",
    "\n",
    "        # 2) Clean / fill missing\n",
    "        df = fill_missing(df)\n",
    "\n",
    "        # 3) Compute features\n",
    "        df = compute_features(df)\n",
    "\n",
    "        # 4) EDA quick stats\n",
    "        print(f\"\\n{ticker} - head:\")\n",
    "        print(df.head(3).to_string())\n",
    "\n",
    "        print(f\"\\n{ticker} - describe (Price):\")\n",
    "        print(df[\"Price\"].describe().to_string())\n",
    "\n",
    "        # 5) Stationarity tests\n",
    "        adf_price = adf_test(df[\"Price\"].dropna(), title=f\"{ticker} Price\")\n",
    "        adf_returns = adf_test(df[\"Daily_Return\"].dropna(), title=f\"{ticker} Daily_Return\")\n",
    "        print(f\"\\nADF test for {ticker} price: ADF={adf_price['ADF Statistic']:.4f}, p={adf_price['p-value']:.4f}, stationary={adf_price['stationary']}\")\n",
    "        print(f\"ADF test for {ticker} returns: ADF={adf_returns['ADF Statistic']:.4f}, p={adf_returns['p-value']:.4f}, stationary={adf_returns['stationary']}\")\n",
    "\n",
    "        # 6) Outlier detection (z-score > 3)\n",
    "        outliers = df[np.abs(df[\"Return_Z\"]) > 3]\n",
    "        print(f\"\\n{ticker} - outliers (|z|>3) count: {len(outliers)}\")\n",
    "        if not outliers.empty:\n",
    "            print(outliers[[\"Price\", \"Daily_Return\", \"Return_Z\"]].head(5).to_string())\n",
    "\n",
    "        # 7) Risk metrics\n",
    "        metrics = compute_risk_metrics(df[\"Daily_Return\"])\n",
    "        metrics.update({\n",
    "            \"ADF_price_pvalue\": adf_price[\"p-value\"],\n",
    "            \"ADF_returns_pvalue\": adf_returns[\"p-value\"],\n",
    "            \"outliers_count\": len(outliers),\n",
    "            \"start_date\": df.index.min().strftime(\"%Y-%m-%d\"),\n",
    "            \"end_date\": df.index.max().strftime(\"%Y-%m-%d\")\n",
    "        })\n",
    "        summary_metrics[ticker] = metrics\n",
    "\n",
    "        # 8) Save csv\n",
    "        save_df(df, os.path.join(OUT_DIR, f\"{ticker}_processed.csv\"))\n",
    "\n",
    "        # 9) Plots\n",
    "        # a) Price over time with rolling mean/std band\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.plot(df.index, df[\"Price\"], label=f\"{ticker} Price\")\n",
    "        ax.plot(df.index, df[f\"Rolling_Mean_{ROLL_WINDOW}\"], label=f\"{ROLL_WINDOW}-day Rolling Mean\")\n",
    "        upper = df[f\"Rolling_Mean_{ROLL_WINDOW}\"] + df[f\"Rolling_Std_{ROLL_WINDOW}\"]\n",
    "        lower = df[f\"Rolling_Mean_{ROLL_WINDOW}\"] - df[f\"Rolling_Std_{ROLL_WINDOW}\"]\n",
    "        ax.fill_between(df.index, lower, upper, alpha=0.15)\n",
    "        ax.set_title(f\"{ticker} Price with {ROLL_WINDOW}-day rolling mean & std\")\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(\"Price (USD)\")\n",
    "        ax.legend()\n",
    "        fig.tight_layout()\n",
    "        ppath = os.path.join(PLOTS_DIR, f\"{ticker}_price_rolling.png\")\n",
    "        fig.savefig(ppath, dpi=150)\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved plot: {ppath}\")\n",
    "\n",
    "        # b) Daily returns plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 4))\n",
    "        ax.plot(df.index, df[\"Daily_Return\"], label=\"Daily Return\")\n",
    "        ax.set_title(f\"{ticker} Daily Returns\")\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(\"Daily Return\")\n",
    "        fig.tight_layout()\n",
    "        rpath = os.path.join(PLOTS_DIR, f\"{ticker}_daily_returns.png\")\n",
    "        fig.savefig(rpath, dpi=150)\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved plot: {rpath}\")\n",
    "\n",
    "        # c) Histogram of returns with VaR line\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "        ax.hist(df[\"Daily_Return\"].dropna(), bins=100)\n",
    "        ax.axvline(metrics[\"VaR_95\"], linestyle=\"--\", linewidth=2, label=f\"VaR 95% = {metrics['VaR_95']:.4f}\")\n",
    "        ax.set_title(f\"{ticker} Returns Distribution\")\n",
    "        ax.set_xlabel(\"Daily Return\")\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "        ax.legend()\n",
    "        hpath = os.path.join(PLOTS_DIR, f\"{ticker}_returns_hist.png\")\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(hpath, dpi=150)\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved plot: {hpath}\")\n",
    "\n",
    "    # 10) Summary table\n",
    "    summary_df = pd.DataFrame.from_dict(summary_metrics, orient=\"index\")\n",
    "    if not summary_df.empty:\n",
    "        summary_df = summary_df[[\"start_date\",\"end_date\",\"mean\",\"std\",\"VaR_95\",\"Sharpe_annual\",\"ADF_price_pvalue\",\"ADF_returns_pvalue\",\"outliers_count\"]]\n",
    "        save_df(summary_df, os.path.join(OUT_DIR, \"summary_metrics.csv\"))\n",
    "        print(\"\\nSummary metrics (head):\")\n",
    "        print(summary_df.head().to_string())\n",
    "    else:\n",
    "        print(\"No summary metrics to save (no data).\")\n",
    "\n",
    "    elapsed = datetime.now() - start_time\n",
    "    print(f\"\\nCompleted Task 1 in {elapsed}. Outputs saved in '{OUT_DIR}' directory.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(\"Error during execution:\", str(e))\n",
    "        sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb25160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "Data downloaded: total 2535 rows, train 2140, test 395\n",
      "Fitting ARIMA model (statsmodels)...\n",
      "ARIMA order used: (5, 1, 0)\n",
      "Saved forecasts: outputs_task2\\tsla_forecasts.csv\n",
      "Saved summary: outputs_task2\\summary.json\n",
      "\n",
      "=== Model evaluation on test set ===\n",
      "Test period: 2024-01-02 -> 2025-07-30 (395 trading days)\n",
      "\n",
      "ARIMA metrics:\n",
      "  MAE: 62.968664\n",
      "  RMSE: 77.985447\n",
      "  MAPE%: 24.076288\n",
      "\n",
      "LSTM metrics:\n",
      "  MAE: 64.401362\n",
      "  RMSE: 80.611215\n",
      "  MAPE%: 24.055137\n",
      "\n",
      "Better model by RMSE: ARIMA\n",
      "\n",
      "All outputs (CSV, plots, summary) saved in: outputs_task2\n",
      "\n",
      "Completed in: 0:01:14.042683\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# ARIMA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# -------------------------\n",
    "# Configuration\n",
    "# -------------------------\n",
    "TICKER = \"TSLA\"\n",
    "START_DATE = \"2015-07-01\"\n",
    "END_DATE = \"2025-07-31\"\n",
    "TRAIN_END = \"2023-12-31\"   # inclusive train end\n",
    "TEST_START = \"2024-01-01\"\n",
    "OUT_DIR = \"outputs_task2\"\n",
    "PLOTS_DIR = os.path.join(OUT_DIR, \"plots\")\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# Utilities\n",
    "# -------------------------\n",
    "def download_tsla(start, end):\n",
    "    df = yf.download(TICKER, start=start, end=end, progress=False)\n",
    "    if df.empty:\n",
    "        raise RuntimeError(\"No data downloaded. Check ticker/date range or internet.\")\n",
    "    if \"Adj Close\" in df.columns:\n",
    "        df[\"Price\"] = df[\"Adj Close\"]\n",
    "    else:\n",
    "        df[\"Price\"] = df[\"Close\"]\n",
    "    df = df[[\"Price\"]]\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    return df\n",
    "\n",
    "def split_train_test(df, train_end):\n",
    "    train = df.loc[:train_end].copy()\n",
    "    test = df.loc[train_end:].copy()\n",
    "    # ensure test begins next trading day after train_end; we will slice properly by TEST_START below\n",
    "    return train, test\n",
    "\n",
    "def evaluate_series(y_true, y_pred):\n",
    "    # y_true, y_pred as 1D arrays aligned\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / np.where(y_true==0, 1e-8, y_true))) * 100\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"MAPE%\": mape}\n",
    "def train_forecast_arima(train_series, n_periods):\n",
    "    print(\"Fitting ARIMA model (statsmodels)...\")\n",
    "    # You can manually tune (p,d,q) or try a few combinations\n",
    "    p, d, q = 5, 1, 0  # Example order\n",
    "    model = ARIMA(train_series, order=(p, d, q))\n",
    "    fitted = model.fit()\n",
    "\n",
    "    forecast_res = fitted.get_forecast(steps=n_periods)\n",
    "    fc = forecast_res.predicted_mean\n",
    "    confint = forecast_res.conf_int()\n",
    "\n",
    "    print(\"ARIMA order used:\", (p, d, q))\n",
    "    return fc.values, confint.values, fitted\n",
    "\n",
    "# -------------------------\n",
    "# LSTM Model\n",
    "# -------------------------\n",
    "def create_sequences(series_values, window):\n",
    "    X, y = [], []\n",
    "    for i in range(window, len(series_values)):\n",
    "        X.append(series_values[i-window:i])\n",
    "        y.append(series_values[i])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    # reshape X for LSTM: (samples, timesteps, features)\n",
    "    return X.reshape((X.shape[0], X.shape[1], 1)), y\n",
    "\n",
    "def train_lstm_forecast(train_series, test_len, window=60, epochs=25, batch_size=32):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(train_series.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # prepare supervised sequences\n",
    "    X_train, y_train = create_sequences(scaled, window)\n",
    "    if X_train.size == 0:\n",
    "        raise RuntimeError(\"Not enough data for LSTM with the chosen window size.\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(X_train.shape[1], 1), return_sequences=False))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    # Train\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    # Forecast iteratively\n",
    "    last_window = scaled[-window:].tolist()\n",
    "    preds_scaled = []\n",
    "    for _ in range(test_len):\n",
    "        x_in = np.array(last_window[-window:]).reshape((1, window, 1))\n",
    "        yhat = model.predict(x_in, verbose=0)[0][0]\n",
    "        preds_scaled.append(yhat)\n",
    "        last_window.append(yhat)  # append predicted scaled value\n",
    "\n",
    "    preds = scaler.inverse_transform(np.array(preds_scaled).reshape(-1, 1)).flatten()\n",
    "    return preds, model, scaler\n",
    "def run_task2():\n",
    "    print(\"Downloading data...\")\n",
    "    df = download_tsla(START_DATE, END_DATE)\n",
    "    # enforce TEST_START slicing\n",
    "    train_df = df.loc[:TRAIN_END].copy()\n",
    "    test_df = df.loc[TEST_START:END_DATE].copy()\n",
    "    if test_df.empty:\n",
    "        raise RuntimeError(\"Test set is empty. Check TEST_START and END_DATE.\")\n",
    "    print(f\"Data downloaded: total {len(df)} rows, train {len(train_df)}, test {len(test_df)}\")\n",
    "\n",
    "    # ---------- ARIMA ----------\n",
    "    arima_horizon = len(test_df)\n",
    "    arima_fc, arima_confint, arima_model = train_forecast_arima(train_df[\"Price\"], arima_horizon)\n",
    "    # align ARIMA forecast index with test_df index\n",
    "    arima_index = test_df.index[:arima_horizon]\n",
    "    arima_series = pd.Series(arima_fc, index=arima_index, name=\"ARIMA_Forecast\")\n",
    "    arima_conf = pd.DataFrame(arima_confint, index=arima_index, columns=[\"lower\", \"upper\"])\n",
    "\n",
    "    # ---------- LSTM ----------\n",
    "    # Use only train data to fit scaler and model; then forecast test_len ahead\n",
    "    lstm_preds, lstm_model, lstm_scaler = train_lstm_forecast(train_df[\"Price\"], test_len=arima_horizon, window=60, epochs=30, batch_size=32)\n",
    "    lstm_series = pd.Series(lstm_preds, index=arima_index, name=\"LSTM_Forecast\")\n",
    "\n",
    "    # ---------- Evaluate ----------\n",
    "    actual = test_df[\"Price\"].loc[arima_index]\n",
    "    arima_metrics = evaluate_series(actual.values, arima_series.values)\n",
    "    lstm_metrics = evaluate_series(actual.values, lstm_series.values)\n",
    "\n",
    "    # Save results\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Actual\": actual,\n",
    "        \"ARIMA_Forecast\": arima_series,\n",
    "        \"LSTM_Forecast\": lstm_series,\n",
    "        \"ARIMA_lower\": arima_conf[\"lower\"],\n",
    "        \"ARIMA_upper\": arima_conf[\"upper\"]\n",
    "    })\n",
    "    results_path = os.path.join(OUT_DIR, \"tsla_forecasts.csv\")\n",
    "    results_df.to_csv(results_path)\n",
    "    print(f\"Saved forecasts: {results_path}\")\n",
    "\n",
    "    # ---------- Plots ----------\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(train_df.index[-500:], train_df[\"Price\"].iloc[-500:], label=\"Train (last 500 days)\")\n",
    "    plt.plot(actual.index, actual.values, label=\"Actual (Test)\", linewidth=1.2)\n",
    "    plt.plot(arima_series.index, arima_series.values, label=\"ARIMA Forecast\", linestyle=\"--\")\n",
    "    plt.plot(lstm_series.index, lstm_series.values, label=\"LSTM Forecast\", linestyle=\":\")\n",
    "    plt.fill_between(arima_conf.index, arima_conf[\"lower\"], arima_conf[\"upper\"], color=\"gray\", alpha=0.2, label=\"ARIMA 95% CI\")\n",
    "    plt.title(f\"{TICKER} Forecasts: ARIMA vs LSTM\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price (USD)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, \"tsla_forecasts_compare.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # Error plots\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(actual.index, (actual.values - arima_series.values), label=\"ARIMA Error\")\n",
    "    plt.plot(actual.index, (actual.values - lstm_series.values), label=\"LSTM Error\")\n",
    "    plt.title(\"Forecast Errors (Actual - Predicted)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, \"tsla_forecast_errors.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # ---------- Summary ----------\n",
    "    summary = {\n",
    "        \"ARIMA_metrics\": arima_metrics,\n",
    "        \"LSTM_metrics\": lstm_metrics,\n",
    "        \"ARIMA_order\": getattr(arima_model, \"order\", None),\n",
    "        \"train_start\": train_df.index.min().strftime(\"%Y-%m-%d\"),\n",
    "        \"train_end\": train_df.index.max().strftime(\"%Y-%m-%d\"),\n",
    "        \"test_start\": actual.index.min().strftime(\"%Y-%m-%d\"),\n",
    "        \"test_end\": actual.index.max().strftime(\"%Y-%m-%d\"),\n",
    "        \"n_test_days\": len(actual)\n",
    "    }\n",
    "    summary_path = os.path.join(OUT_DIR, \"summary.json\")\n",
    "    import json\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"Saved summary: {summary_path}\")\n",
    "\n",
    "    # Print human-readable summary\n",
    "    print(\"\\n=== Model evaluation on test set ===\")\n",
    "    print(f\"Test period: {summary['test_start']} -> {summary['test_end']} ({summary['n_test_days']} trading days)\")\n",
    "    print(\"\\nARIMA metrics:\")\n",
    "    for k,v in arima_metrics.items():\n",
    "        print(f\"  {k}: {v:.6f}\")\n",
    "    print(\"\\nLSTM metrics:\")\n",
    "    for k,v in lstm_metrics.items():\n",
    "        print(f\"  {k}: {v:.6f}\")\n",
    "\n",
    "    # Which performed better?\n",
    "    def better(a,b,metric=\"RMSE\"):\n",
    "        return \"ARIMA\" if a[metric] < b[metric] else \"LSTM\"\n",
    "    better_rmse = better(arima_metrics, lstm_metrics, \"RMSE\")\n",
    "    print(f\"\\nBetter model by RMSE: {better_rmse}\")\n",
    "\n",
    "    print(\"\\nAll outputs (CSV, plots, summary) saved in:\", OUT_DIR)\n",
    "    return summary, results_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = datetime.now()\n",
    "    summary, results_df = run_task2()\n",
    "    print(\"\\nCompleted in:\", datetime.now() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa5597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "def train_forecast_arima(train_series, n_periods, order=(5,1,0)):\n",
    "    model = ARIMA(train_series, order=order)\n",
    "    fitted = model.fit()\n",
    "    forecast_res = fitted.get_forecast(steps=n_periods)\n",
    "    forecast = forecast_res.predicted_mean\n",
    "    conf_int = forecast_res.conf_int()\n",
    "    return forecast, conf_int, fitted\n",
    "\n",
    "def evaluate_forecast(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return mae, rmse\n",
    "\n",
    "def plot_forecasts(train_df, test_df, arima_fc, arima_confint):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_df.index, train_df['Price'], label='Train', color='blue')\n",
    "    plt.plot(test_df.index, test_df['Price'], label='Test', color='orange')\n",
    "    plt.plot(test_df.index, arima_fc, label='ARIMA Forecast', color='green')\n",
    "    plt.fill_between(test_df.index,\n",
    "                     arima_confint.iloc[:, 0],\n",
    "                     arima_confint.iloc[:, 1],\n",
    "                     color='k', alpha=0.1)\n",
    "    plt.legend()\n",
    "    plt.title('ARIMA Forecast vs Actual')\n",
    "    plt.show()\n",
    "\n",
    "def run_task2():\n",
    "    # Load data\n",
    "    df = pd.read_csv(\"brent_daily.csv\", parse_dates=['Date'])\n",
    "    df = df.sort_values(\"Date\").set_index(\"Date\")\n",
    "    df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Train-test split (80/20)\n",
    "    split_index = int(len(df) * 0.8)\n",
    "    train_df = df.iloc[:split_index]\n",
    "    test_df = df.iloc[split_index:]\n",
    "\n",
    "    # ARIMA forecast\n",
    "    arima_horizon = len(test_df)\n",
    "    arima_order = (5, 1, 0)  # You can adjust\n",
    "    arima_fc, arima_confint, arima_model = train_forecast_arima(train_df['Price'], arima_horizon, order=arima_order)\n",
    "\n",
    "    # Evaluation\n",
    "    mae, rmse = evaluate_forecast(test_df['Price'], arima_fc)\n",
    "\n",
    "    # Results summary\n",
    "    results_df = pd.DataFrame({\n",
    "        'Actual': test_df['Price'],\n",
    "        'Forecast': arima_fc\n",
    "    }, index=test_df.index)\n",
    "\n",
    "    plot_forecasts(train_df, test_df, arima_fc, arima_confint)\n",
    "\n",
    "    summary = {\n",
    "        \"ARIMA Order\": arima_order,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse\n",
    "    }\n",
    "    return summary, results_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = datetime.now()\n",
    "    summary, results_df = run_task2()\n",
    "    print(\"\\nSummary Metrics:\")\n",
    "    for k, v in summary.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    print(\"\\nResults head:\")\n",
    "    print(results_df.head())\n",
    "    print(\"\\nCompleted in:\", datetime.now() - start)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
